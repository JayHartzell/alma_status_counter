{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from asyncio_throttle import Throttler\n",
    "import os\n",
    "import dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv keys.env\n",
    "\n",
    "api_key = os.getenv('bibKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_id = ''\n",
    "holding_ids = ['', '', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_calls(url, throttler=None):\n",
    "    \n",
    "    \"\"\"Makes a GET call using the url passed in. The item object is parsed as JSON, \n",
    "    the inventory price is mapped to replacement cost, and the object is PUT back to Alma.\"\"\"\n",
    "    items = []\n",
    "    offset = 0\n",
    "    limit = 100  # Adjust this based on your API's pagination size\n",
    "    total_record_count = float('inf')  # Initialize with a large value\n",
    "\n",
    "    headers = {\n",
    "        'apiKey': api_key, \n",
    "        'format': 'json',\n",
    "        'limit' : str(limit),\n",
    "        'offset' : str(offset)\n",
    "    }\n",
    "\n",
    "    while offset < total_record_count:\n",
    "        async with throttler:\n",
    "            try:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    response = await session.get(url, params=headers)\n",
    "\n",
    "                    item_object = await response.json()\n",
    "                   \n",
    "                    items.append(item_object)\n",
    "\n",
    "                    # Increment the offset by the 'limit' for the next page\n",
    "                    offset += limit\n",
    "\n",
    "                    # Update total_record_count if it's not already set\n",
    "                    if 'total_record_count' in item_object and total_record_count == float('inf'):\n",
    "                        total_record_count = item_object['total_record_count']\n",
    "\n",
    "                # If we have reached the total count, exit the loop\n",
    "                if offset >= total_record_count:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                # Handle other exceptions (e.g., network issues)\n",
    "                print(f'{e} for {url}')\n",
    "                break  # Exit the loop on exception\n",
    "\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_tasks(urls):\n",
    "    \"\"\"Gather tasks for making calls to the Alma API.\"\"\"\n",
    "    throttler = Throttler(rate_limit=20)\n",
    "    #  Create a list of tasks\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        task = asyncio.create_task(make_calls(url, throttler=throttler))\n",
    "        tasks.append(task)\n",
    "\n",
    "\n",
    "    # Wait for all of the tasks to finish\n",
    "    item_list = await asyncio.gather(*tasks)\n",
    "\n",
    "    return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates the URL endpoints needed to make citation requests.\n",
    "def build_url(holding_ids, mms_id): \n",
    "    a = []\n",
    "    for i in holding_ids:\n",
    "        holding_id = i\n",
    "\n",
    "        url = f\"https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items\"\n",
    "\n",
    "        a.append(url)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_values(response_list):\n",
    "    values = []\n",
    "    for i in response_list:\n",
    "        for j in i['item']:\n",
    "            values.append(j)\n",
    "                       \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(unpacked): \n",
    "        \n",
    "    temp_location_count = len([i for i in unpacked if i['holding_data']['in_temp_location'] == True])\n",
    "    base_status_0_count = len([i for i in unpacked if i['item_data']['base_status']['value'] == '0'])\n",
    "    base_status_1_count = len([i for i in unpacked if i['item_data']['base_status']['value'] == '1'])\n",
    "    holding_id = unpacked[0]['holding_data']['holding_id']\n",
    "    location = unpacked[0]['item_data']['location']['desc']\n",
    "    material_type = unpacked[0]['item_data']['physical_material_type']['value']\n",
    "    base_status_0_process_types = {}\n",
    "\n",
    "    for i in unpacked:\n",
    "        if i['item_data']['base_status']['value'] == '0':\n",
    "            process_type = i['item_data']['process_type']['value']\n",
    "            if process_type not in base_status_0_process_types:\n",
    "                base_status_0_process_types[process_type] = 1\n",
    "            else:\n",
    "                process_count = base_status_0_process_types.get(process_type, 0)\n",
    "                process_count += 1\n",
    "                base_status_0_process_types[process_type] = process_count\n",
    "\n",
    "  \n",
    "    a =  {  'holding_id': holding_id,\n",
    "                'location' : location,\n",
    "                'items_in_place': base_status_1_count,\n",
    "                'items_not_in_place': base_status_0_count,\n",
    "                'items_nip_process': base_status_0_process_types,\n",
    "                'temp_location_count': temp_location_count, \n",
    "                'material_type': material_type\n",
    "                }\n",
    "    \n",
    "    \n",
    "    print(f'Inventory counts for Holding ID: {a[\"holding_id\"]} in {a[\"location\"]} with material type: {a[\"material_type\"]}') \n",
    "    print(f'Available for checkout: {a[\"items_in_place\"]}')\n",
    "    print(f'In temp location: {a[\"temp_location_count\"]}')\n",
    "    print(f'Items not in place: {a[\"items_not_in_place\"]}, with process types: {a[\"items_nip_process\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_response(json, holding_id):\n",
    "    unpacked = unpack_values(json)\n",
    "    counts = get_counts(unpacked)\n",
    "    return holding_id, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    urls = build_url(holding_ids, mms_id)\n",
    "    item_responses = await gather_tasks(urls)\n",
    "\n",
    "    holding_counts = {}  # Dictionary to store counts for each holding ID\n",
    "\n",
    "    for holding_id, response in zip(holding_ids, item_responses):\n",
    "        holding_id, counts = await process_response(response, holding_id)\n",
    "        if counts is not None:\n",
    "            holding_counts[holding_id] = counts\n",
    "\n",
    "    # Print the counts for each holding ID\n",
    "    for holding_id, counts in holding_counts.items():\n",
    "        print(f'Inventory counts for Holding ID: {holding_id} in {counts.get(\"location\", \"N/A\")} ({counts[\"material_type\"]})')\n",
    "        print(f'Available for checkout: {counts.get(\"items_in_place\", 0)}')\n",
    "        print(f'In temp location: {counts.get(\"temp_location_count\", 0)}')\n",
    "        print(f'Items not in place: {counts.get(\"items_not_in_place\", 0)}, with process types: {counts.get(\"items_nip_process\", {})}')\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = build_url(holding_ids, mms_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_responses = await gather_tasks(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
