{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "from asyncio_throttle import Throttler\n",
    "import os\n",
    "import dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv keys.env\n",
    "\n",
    "api_key = os.getenv('bibKey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_id = ['',  ''] # enter mms_ids, matched to the order of the list of holding ids\n",
    "holding_ids = [['', ''],['']] # enter your mms's holding id's as separate lists within the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def make_calls(url, throttler=None):\n",
    "    \n",
    "    items = []\n",
    "    \n",
    "    total_record_count = float('inf')  # Initialize with a large value\n",
    "\n",
    "    headers = {\n",
    "        'apiKey': api_key, \n",
    "        'format': 'json',\n",
    "        'limit' : 100,\n",
    "        'offset' : 0\n",
    "    }\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        while headers['offset'] < total_record_count:\n",
    "            try:\n",
    "                response = await session.get(url, params=headers)\n",
    "                item_object = await response.json()\n",
    "\n",
    "                items.append(item_object)\n",
    "\n",
    "                # Increment the offset by the 'limit' for the next page\n",
    "                headers['offset'] += 100\n",
    "\n",
    "                # Update total_record_count if it's not already set\n",
    "                if 'total_record_count' in item_object and total_record_count == float('inf'):\n",
    "                    total_record_count = item_object['total_record_count']\n",
    "\n",
    "                # If we have reached the total count, exit the loop\n",
    "                if headers['offset'] >= total_record_count:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                # Handle other exceptions (e.g., network issues)\n",
    "                print(f'{e} for {url}')\n",
    "                break \n",
    "\n",
    "    return items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def gather_tasks(urls):\n",
    "    \"\"\"Gather tasks for making calls to the Alma API.\"\"\"\n",
    "    throttler = Throttler(rate_limit=20)\n",
    "    #  Create a list of tasks\n",
    "    tasks = []\n",
    "    for url in urls:\n",
    "        task = asyncio.create_task(make_calls(url, throttler=throttler))\n",
    "        tasks.append(task)\n",
    "\n",
    "\n",
    "    # Wait for all of the tasks to finish\n",
    "    item_list = await asyncio.gather(*tasks)\n",
    "\n",
    "    return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url(mms_ids, holding_ids_list):\n",
    "    urls = []\n",
    "    for mms_id, holding_ids in zip(mms_ids, holding_ids_list):\n",
    "        mms_urls = [f'https://api-na.hosted.exlibrisgroup.com/almaws/v1/bibs/{mms_id}/holdings/{holding_id}/items' for holding_id in holding_ids]\n",
    "        urls.extend(mms_urls)\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_values(response_list):\n",
    "    values = []\n",
    "    \n",
    "    for i in response_list:\n",
    "        for j in i['item']:\n",
    "            values.append(j)\n",
    "                       \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(unpacked): \n",
    "        \n",
    "    temp_location_count = len([i for i in unpacked if i['holding_data']['in_temp_location'] == True])\n",
    "    base_status_0_count = len([i for i in unpacked if i['item_data']['base_status']['value'] == '0'])\n",
    "    base_status_1_count = len([i for i in unpacked if i['item_data']['base_status']['value'] == '1'])\n",
    "    holding_id = unpacked[0]['holding_data']['holding_id']\n",
    "    location = unpacked[0]['item_data']['location']['desc']\n",
    "    material_type = unpacked[0]['item_data']['physical_material_type']['value']\n",
    "    base_status_0_process_types = {}\n",
    "\n",
    "    for i in unpacked:\n",
    "        if i['item_data']['base_status']['value'] == '0':\n",
    "            process_type = i['item_data']['process_type']['value']\n",
    "            if process_type not in base_status_0_process_types:\n",
    "                base_status_0_process_types[process_type] = 1\n",
    "            else:\n",
    "                process_count = base_status_0_process_types.get(process_type, 0)\n",
    "                process_count += 1\n",
    "                base_status_0_process_types[process_type] = process_count\n",
    "\n",
    "  \n",
    "    a =  {  'holding_id': holding_id,\n",
    "                'location' : location,\n",
    "                'items_in_place': base_status_1_count,\n",
    "                'items_not_in_place': base_status_0_count,\n",
    "                'items_nip_process': base_status_0_process_types,\n",
    "                'temp_location_count': temp_location_count, \n",
    "                'material_type': material_type\n",
    "                }\n",
    "    \n",
    "    \n",
    "    print(f'Inventory counts for Holding ID: {a[\"holding_id\"]} in {a[\"location\"]} with material type: {a[\"material_type\"]}') \n",
    "    print(f'Available for checkout: {a[\"items_in_place\"] - a[\"temp_location_count\"]}')\n",
    "    print(f'In temp location: {a[\"temp_location_count\"]}')\n",
    "    print(f'Items not in place: {a[\"items_not_in_place\"]}, with process types: {a[\"items_nip_process\"]}')\n",
    "    print('\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urls = build_url(mms_id, holding_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_responses = await gather_tasks(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inventory counts for Holding ID: 2249469840005274 in 7 Day Tech with material type: LPTOP\n",
      "Available for checkout: 47\n",
      "In temp location: 17\n",
      "Items not in place: 608, with process types: {'MISSING': 11, 'LOAN': 476, 'LOST_LOAN': 114, 'LOST_LOAN_AND_PAID': 6, 'TRANSIT': 1}\n",
      "\n",
      "\n",
      "Inventory counts for Holding ID: 2249449370005274 in CLC Info with material type: LPTOP\n",
      "Available for checkout: 4\n",
      "In temp location: 1\n",
      "Items not in place: 10, with process types: {'LOAN': 10}\n",
      "\n",
      "\n",
      "Inventory counts for Holding ID: 2280943670005274 in 7 Day Tech with material type: MOBILEDEVICE\n",
      "Available for checkout: 14\n",
      "In temp location: 8\n",
      "Items not in place: 509, with process types: {'LOAN': 427, 'LOST_LOAN': 70, 'LOST_LOAN_AND_PAID': 9, 'WORK_ORDER_DEPARTMENT': 1, 'TRANSIT': 1, 'HOLDSHELF': 1}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in item_responses:\n",
    "    unpacked = unpack_values(i)\n",
    "    get_counts(unpacked)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
